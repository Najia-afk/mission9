# Mission 9 - Big Data Cloud with AWS EMR

Distributed image feature extraction pipeline using PySpark and TensorFlow on AWS EMR.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              LOCAL MACHINE                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Docker Compose                                                          â”‚    â”‚
â”‚  â”‚  â”œâ”€â”€ terraform (v1.6)     â”€â”€â”€ terraform apply â”€â”€â”€â”                      â”‚    â”‚
â”‚  â”‚  â””â”€â”€ aws-cli (v2)         â”€â”€â”€ aws emr/s3 â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚ AWS API
                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AWS CLOUD (eu-west-1 - GDPR COMPLIANT)                       â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ğŸ“¦ S3 Bucket       â”‚    â”‚  âš¡ EMR Cluster (emr-6.15.0)                   â”‚   â”‚
â”‚  â”‚  mission9-data-*   â”‚    â”‚                                                â”‚   â”‚
â”‚  â”‚                    â”‚â—„â”€â”€â”€â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ fruits-360/   â”‚    â”‚  â”‚  Master (m5.xlarge)                      â”‚  â”‚   â”‚
â”‚  â”‚  â”‚   â”œâ”€â”€ Training/ â”‚    â”‚  â”‚  â”œâ”€â”€ JupyterHub :9443 (HTTPS)            â”‚  â”‚   â”‚
â”‚  â”‚  â”‚   â””â”€â”€ Test/     â”‚    â”‚  â”‚  â””â”€â”€ Spark Driver                        â”‚  â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Results/      â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Results_PCA/  â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚  â””â”€â”€ Results_CSV/  â”‚    â”‚  â”‚  Worker 1        â”‚ â”‚  Worker 2        â”‚     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚  Spark Executor  â”‚ â”‚  Spark Executor  â”‚     â”‚   â”‚
â”‚                            â”‚  â”‚  TensorFlow      â”‚ â”‚  TensorFlow      â”‚     â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â”‚  ğŸ” IAM Roles       â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚  ğŸ›¡ï¸ Security Groupsâ”‚                                                         â”‚
â”‚  â”‚    (port 9443 only)â”‚                                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### 1. Configure AWS Credentials

```bash
cp .env.example .env
# Edit .env with your AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY
```

### 2. Deploy to AWS (One Command)

```bash
# Initialize and deploy infrastructure
docker compose --profile deploy run --rm terraform init
docker compose --profile deploy run --rm terraform apply -auto-approve
```

**The bootstrap script automatically:**
- âœ… Installs TensorFlow, Pandas, Pillow on all nodes
- âœ… Installs Java in JupyterHub container (for PySpark)
- âœ… Downloads & uploads Fruits-360 dataset (~90K images) to S3

### 3. Access JupyterHub

After ~15 minutes, get the URL:
```bash
docker compose --profile deploy run --rm terraform output jupyterhub_url
# â†’ https://ec2-xx-xx-xx-xx.eu-west-1.compute.amazonaws.com:9443
```

**Credentials:** `jovyan` / `jupyter`

### 4. Run the Notebook

1. Upload `notebooks/mission9_emr.ipynb` to JupyterHub
2. Click **Run All** cells
3. Wait for processing (~10-20 min for full dataset)

### 5. Cleanup (Important!)

```bash
# Destroy all AWS resources to avoid charges
docker compose --profile deploy run --rm terraform destroy -auto-approve
```

## ğŸ“Š Pipeline Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ S3      â”‚â”€â”€â”€â–¶â”‚ Spark Read  â”‚â”€â”€â”€â–¶â”‚ MobileNetV2 â”‚â”€â”€â”€â–¶â”‚ PCA â”‚â”€â”€â”€â–¶â”‚ S3       â”‚
â”‚ Images  â”‚    â”‚ binaryFile  â”‚    â”‚ 1280 feat   â”‚    â”‚ 50  â”‚    â”‚ Parquet  â”‚
â”‚ 90K     â”‚    â”‚ DataFrame   â”‚    â”‚ broadcast   â”‚    â”‚ dim â”‚    â”‚ + CSV    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
mission9/
â”œâ”€â”€ ğŸ““ notebooks/
â”‚   â””â”€â”€ mission9_emr.ipynb      # Main PySpark notebook (run on EMR)
â”œâ”€â”€ ğŸ—ï¸ infra/
â”‚   â””â”€â”€ main.tf                  # Terraform infrastructure (S3, EMR, IAM)
â”œâ”€â”€ ğŸ¨ presentation/
â”‚   â”œâ”€â”€ generate_ppt.py          # PowerPoint generator (AWS theme)
â”‚   â””â”€â”€ generate_diagrams.py     # Architecture diagrams
â”œâ”€â”€ ğŸ“Š reports/
â”‚   â””â”€â”€ skill_grid.md            # Competencies validation (9/9 âœ…)
â”œâ”€â”€ ğŸ³ docker-compose.yml        # Local dev + deploy services
â”œâ”€â”€ ğŸ“¦ Dockerfile                # Python + Spark + TensorFlow
â””â”€â”€ ğŸ“‹ requirements.txt          # Dependencies
```

## ğŸ›¡ï¸ GDPR Compliance

| Requirement | Implementation |
|-------------|----------------|
| **Region** | `eu-west-1` (Ireland) - EU territory |
| **Data Residency** | All data stored & processed in EU |
| **S3 Security** | Public access blocked |
| **Network** | Only port 9443 (JupyterHub) exposed |

## ğŸ“œ License

- **Project**: MIT License
- **Dataset**: Fruits-360 by Horea Muresan & Mihai Oltean (Public Domain)
- **Model**: MobileNetV2 (Apache 2.0)
