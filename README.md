# Mission 9 - Big Data Cloud with AWS EMR

[![Python](https://img.shields.io/badge/Python-3.9-blue.svg)](https://www.python.org/)
[![PySpark](https://img.shields.io/badge/PySpark-3.4-orange.svg)](https://spark.apache.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-orange.svg)](https://www.tensorflow.org/)
[![AWS EMR](https://img.shields.io/badge/AWS_EMR-6.15-yellow.svg)](https://aws.amazon.com/emr/)
[![Terraform](https://img.shields.io/badge/Terraform-1.5-purple.svg)](https://www.terraform.io/)
[![Docker](https://img.shields.io/badge/Docker-24.0+-blue.svg)](https://www.docker.com/)

Distributed image feature extraction pipeline using PySpark and TensorFlow on AWS EMR.

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              LOCAL MACHINE                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Docker Compose                                                          â”‚    â”‚
â”‚  â”‚  â”œâ”€â”€ terraform (v1.6)     â”€â”€â”€ terraform apply â”€â”€â”€â”                      â”‚    â”‚
â”‚  â”‚  â””â”€â”€ aws-cli (v2)         â”€â”€â”€ aws emr/s3 â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚ AWS API
                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AWS CLOUD (eu-west-1 - GDPR COMPLIANT)                       â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ðŸ“¦ S3 Bucket       â”‚    â”‚  âš¡ EMR Cluster (emr-6.15.0)                   â”‚   â”‚
â”‚  â”‚  mission9-data-*   â”‚    â”‚                                                â”‚   â”‚
â”‚  â”‚                    â”‚â—„â”€â”€â”€â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ fruits-360/   â”‚    â”‚  â”‚  Master (m5.xlarge)                      â”‚  â”‚   â”‚
â”‚  â”‚  â”‚   â”œâ”€â”€ Training/ â”‚    â”‚  â”‚  â”œâ”€â”€ JupyterHub :9443 (HTTPS)            â”‚  â”‚   â”‚
â”‚  â”‚  â”‚   â””â”€â”€ Test/     â”‚    â”‚  â”‚  â””â”€â”€ Spark Driver                        â”‚  â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Results/      â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Results_PCA/  â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚  â””â”€â”€ Results_CSV/  â”‚    â”‚  â”‚  Worker 1        â”‚ â”‚  Worker 2        â”‚     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚  Spark Executor  â”‚ â”‚  Spark Executor  â”‚     â”‚   â”‚
â”‚                            â”‚  â”‚  TensorFlow      â”‚ â”‚  TensorFlow      â”‚     â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â”‚  ðŸ” IAM Roles       â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚  ðŸ›¡ï¸ Security Groupsâ”‚                                                         â”‚
â”‚  â”‚    (port 9443 only)â”‚                                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Quick Start

### 1. Configure AWS Credentials

```bash
cp .env.example .env
# Edit .env with your AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY
```

### 2. Deploy to AWS (One Command)

```bash
# Initialize and deploy infrastructure
docker compose --profile deploy run --rm terraform init
docker compose --profile deploy run --rm terraform apply -auto-approve
```

**The bootstrap script automatically:**
- âœ… Installs TensorFlow, Pandas, Pillow on all nodes
- âœ… Installs Java in JupyterHub container (for PySpark)
- âœ… Downloads & uploads Fruits-360 dataset (~90K images) to S3

### 3. Access JupyterHub

After ~15 minutes, get the URL:
```bash
docker compose --profile deploy run --rm terraform output jupyterhub_url
# â†’ https://ec2-xx-xx-xx-xx.eu-west-1.compute.amazonaws.com:9443
```

**Credentials:** `jovyan` / `jupyter`

### 4. Run the Notebook

1. Upload `notebooks/mission9_emr.ipynb` to JupyterHub
2. Click **Run All** cells
3. Wait for processing (~10-20 min for full dataset)

### 5. Cleanup (Important!)

```bash
# Destroy all AWS resources to avoid charges
docker compose --profile deploy run --rm terraform destroy -auto-approve
```

## ðŸ“Š Pipeline Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ S3      â”‚â”€â”€â”€â–¶â”‚ Spark Read  â”‚â”€â”€â”€â–¶â”‚ MobileNetV2 â”‚â”€â”€â”€â–¶â”‚ PCA â”‚â”€â”€â”€â–¶â”‚ S3       â”‚
â”‚ Images  â”‚    â”‚ binaryFile  â”‚    â”‚ 1280 feat   â”‚    â”‚ 50  â”‚    â”‚ Parquet  â”‚
â”‚ 90K     â”‚    â”‚ DataFrame   â”‚    â”‚ broadcast   â”‚    â”‚ dim â”‚    â”‚ + CSV    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“ Project Structure

```
mission9/
â”œâ”€â”€ ðŸ““ notebooks/
â”‚   â””â”€â”€ mission9_emr.ipynb      # Main PySpark notebook (run on EMR)
â”œâ”€â”€ ðŸ—ï¸ infra/
â”‚   â””â”€â”€ main.tf                  # Terraform infrastructure (S3, EMR, IAM)
â”œâ”€â”€ ðŸŽ¨ presentation/
â”‚   â”œâ”€â”€ generate_ppt.py          # PowerPoint generator (AWS theme)
â”‚   â””â”€â”€ generate_diagrams.py     # Architecture diagrams
â”œâ”€â”€ ðŸ“Š reports/
â”‚   â””â”€â”€ skill_grid.md            # Competencies validation (9/9 âœ…)
â”œâ”€â”€ ðŸ³ docker-compose.yml        # Local dev + deploy services
â”œâ”€â”€ ðŸ“¦ Dockerfile                # Python + Spark + TensorFlow
â””â”€â”€ ðŸ“‹ requirements.txt          # Dependencies
```

## ðŸ›¡ï¸ GDPR Compliance

| Requirement | Implementation |
|-------------|----------------|
| **Region** | `eu-west-1` (Ireland) - EU territory |
| **Data Residency** | All data stored & processed in EU |
| **S3 Security** | Public access blocked |
| **Network** | Only port 9443 (JupyterHub) exposed |

## ðŸ“œ License & Credits

### Dataset
**Fruits-360** dataset by Horea Muresan & Mihai Oltean  
BabeÈ™-Bolyai University, Cluj-Napoca, Romania

> Horea Muresan, Mihai Oltean, *Fruit recognition from images using deep learning*,  
> Acta Univ. Sapientiae, Informatica Vol. 10, Issue 1, pp. 26-42, 2018.

- ðŸ“„ Paper: [DOI: 10.2478/ausi-2018-0002](https://doi.org/10.2478/ausi-2018-0002)
- ðŸ“¦ Dataset: [Kaggle - Fruits-360](https://www.kaggle.com/datasets/moltean/fruits)
- ðŸ”— GitHub: [Horea94/Fruit-Images-Dataset](https://github.com/Horea94/Fruit-Images-Dataset)

### Pre-trained Model
**MobileNetV2** - Google Inc. (Apache 2.0 License)
